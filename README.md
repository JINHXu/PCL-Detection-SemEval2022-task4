# JD at SemEval2022-task4: PCL detection

Code repository for our paper: 

__JD at SemEval2022 Task 4: RoBERTa vs Traditional Ensemble Models for Patronizing and Condescending Language Detection.__

Authors: [Jinghua Xu](https://jinhxu.github.io/), [Diana Constantina HÃ¶fels]()

### shared-task

* [SemEval2022 Task 4: Patronizing and Condescending Language Detection](https://sites.google.com/view/pcl-detection-semeval2022/)

### abstract

> This paper describes our contribution to SemEval-2022, Task 4: Patronizing and Condescending Language Detection. We participate in both subtasks: PCL identification and PCL categorization, with our main focus put on subtask 1. Our experiments compare traditional ensemble models against pretrained language model RoBERTa. Our top-performing system is ranked 27 out of 80 teams (F1-score: 0.5464) in subtask 1, and 23 out of 50 teams (F1-score: 0.3003) in subtask 2.

### code

* run `export PYTHONPATH="${PYTHONPATH}:path_to_wd/"` in terminal before running each script

### data

* upon request, [info](https://github.com/Perez-AlmendrosC/dontpatronizeme).